{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn_v2\n",
    "from torchvision.models.resnet import Bottleneck, ResNet\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "from sklearn.model_selection import KFold\n",
    "from glob import glob\n",
    "from skimage.measure import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#FLAGS, IMPORTANT!\n",
    "pretrained_lunit = False\n",
    "randstain_aug = True\n",
    "dilated_masks = True\n",
    "#normalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class model_config:\n",
    "    seed = 42\n",
    "    train_batch_size = 8\n",
    "    valid_batch_size = 8\n",
    "    epochs = 50 # ~24 minutes per 10 epoch for 1 fold\n",
    "    CV_fold = 5\n",
    "    learning_rate = 0.0005\n",
    "    scheduler = \"CosineAnnealingLR\"\n",
    "    num_training_samples = 1300\n",
    "    T_max = int(num_training_samples/ train_batch_size * epochs)  # number of iterations for a full cycle, need to change for different # of iterations. (iteration = batch size)\n",
    "    weight_decay = 1e-6  # explore different weight decay (Adam optimizer)\n",
    "    n_accumulate = 1\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    iters_to_accumulate = max(1, 32 // train_batch_size)  # for scaling accumulated gradients\n",
    "    eta_min = 1e-5\n",
    "    model_save_directory = os.path.join(os.getcwd(), \"model\",\n",
    "                                        \"baseline_rcnn\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed) #numpy specific random\n",
    "    random.seed(seed) # python specific random (also for albumentation augmentations)\n",
    "    torch.manual_seed(seed) # torch specific random\n",
    "    torch.cuda.manual_seed(seed) # cuda specific random\n",
    "    # when running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False # when deterministic = true, benchmark = False, otherwise might not be deterministic\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # set a fixed value for the hash seed, for hases like dictionary\n",
    "\n",
    "set_seed(model_config.seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_rcnn_model_backbone():\n",
    "    model = maskrcnn_resnet50_fpn_v2(weights= None, num_classes = 2, weights_backbone = None, trainable_backbone_layers = 5)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ResNetTrunk(ResNet):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        del self.fc  # remove FC layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "def get_pretrained_url(key):\n",
    "    URL_PREFIX = \"https://github.com/lunit-io/benchmark-ssl-pathology/releases/download/pretrained-weights\"\n",
    "    model_zoo_registry = {\n",
    "        \"BT\": \"bt_rn50_ep200.torch\",\n",
    "        \"MoCoV2\": \"mocov2_rn50_ep200.torch\",\n",
    "        \"SwAV\": \"swav_rn50_ep200.torch\",\n",
    "    }\n",
    "    pretrained_url = f\"{URL_PREFIX}/{model_zoo_registry.get(key)}\"\n",
    "    return pretrained_url\n",
    "\n",
    "\n",
    "def resnet50(pretrained, progress, key, **kwargs):\n",
    "    model = ResNetTrunk(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_url = get_pretrained_url(key)\n",
    "        verbose = model.load_state_dict(\n",
    "            torch.hub.load_state_dict_from_url(pretrained_url, progress=progress)\n",
    "        )\n",
    "        print(verbose)\n",
    "    return model\n",
    "#\n",
    "#\n",
    "if __name__ == \"__main__\":\n",
    "    # initialize resnet50 trunk using BT pre-trained weight\n",
    "    pretrained_model_backbone = resnet50(pretrained=True, progress=False, key=\"MoCoV2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    transforms = []\n",
    "    transforms.append(T.PILToTensor())\n",
    "    transforms.append(T.ConvertImageDtype(torch.float))\n",
    "    # no transforms, horizontal/vertical will mess up labels\n",
    "    # if train:\n",
    "    return T.Compose(transforms)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class HubmapDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs, masks, transforms):\n",
    "        self.transforms = transforms\n",
    "        self.imgs = imgs\n",
    "        self.masks = masks\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        img_path = self.imgs[idx]\n",
    "        mask_path = self.masks[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "        # convert the PIL Image into a numpy array\n",
    "        mask = np.array(mask)\n",
    "        # instances are encoded as different colors\n",
    "        labelmask = label(mask)\n",
    "        obj_ids = np.unique(labelmask)\n",
    "        # first id is the background, so remove it\n",
    "        obj_ids = obj_ids[1:]\n",
    "        masks = [labelmask== x for x in range(len(obj_ids))]\n",
    "        masks = np.array(masks)\n",
    "        # get bounding box coordinates for each mask\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.nonzero(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        # convert everything into a torch.Tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        try:\n",
    "            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "            #print(area,area.shape,area.dtype)\n",
    "        except:\n",
    "            area = torch.tensor([[0],[0]])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        #print(masks.shape)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = build_rcnn_model_backbone()\n",
    "if pretrained_lunit:\n",
    "    pretrained_weights = r\"C:\\Users\\Kevin\\PycharmProjects\\hubmap\\SSL-pretrained-weights\\lunit\\mocov2_rn50_ep200.torch\"\n",
    "    model.backbone.body = pretrained_model_backbone"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_path = r\"\\\\fatherserverdw\\Kevin\\hubmap\\maskrcnn\\images\\*.tif\"\n",
    "if dilated_masks:\n",
    "    mask_path = r\"\\\\fatherserverdw\\Kevin\\hubmap\\maskrcnn\\masks\\blood_vessel_dilated\\*.png\"\n",
    "else:\n",
    "    mask_path = r\"\\\\fatherserverdw\\Kevin\\hubmap\\maskrcnn\\masks\\blood_vessel\\*.png\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_imgs = len(glob(image_path))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=model_config.seed)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(range(n_imgs))):\n",
    "    if i!=0: continue\n",
    "    all_imgs = sorted(glob(image_path))\n",
    "    all_masks = sorted(glob(mask_path))\n",
    "    all_imgs = np.array(all_imgs)\n",
    "    all_masks = np.array(all_masks)\n",
    "    train_img = all_imgs[train_index]\n",
    "    train_mask = all_masks[train_index]\n",
    "    val_img = all_imgs[test_index]\n",
    "    val_mask = all_masks[test_index]\n",
    "    dataset_train = HubmapDataset(train_img, train_mask, get_transform())\n",
    "    dataset_val = HubmapDataset(val_img, val_mask, get_transform())\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "        dataset_train, batch_size=model_config.train_batch_size, shuffle=True, num_workers=0, pin_memory=True, drop_last=True, collate_fn=utils.collate_fn)\n",
    "    val_dl = torch.utils.data.DataLoader(\n",
    "        dataset_val, batch_size=model_config.valid_batch_size, shuffle=False, num_workers=0, pin_memory=True,collate_fn=utils.collate_fn)\n",
    "\n",
    "    model = build_rcnn_model_backbone()\n",
    "    if pretrained_lunit:\n",
    "        pretrained_weights = r\"C:\\Users\\Kevin\\PycharmProjects\\hubmap\\SSL-pretrained-weights\\lunit\\mocov2_rn50_ep200.torch\"\n",
    "        model.backbone.body = pretrained_model_backbone\n",
    "    model.to(model_config.device)\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.Adam(params, lr=model_config.learning_rate, weight_decay=model_config.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "    for epoch in range(model_config.epochs):\n",
    "        train_one_epoch(model, optimizer, train_dl, model_config.device, epoch, print_freq=50)\n",
    "        evaluate(model, val_dl, device=model_config.device)\n",
    "        scheduler.step()\n",
    "        model_path = os.path.join(model_config.model_save_directory,f'fold_{i}_epoch{epoch}.pth')\n",
    "        torch.save(model.state_dict(), model_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
