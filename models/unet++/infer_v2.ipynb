{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "# from pycocotools import _mask as coco_mask\n",
    "import typing as t\n",
    "import zlib\n",
    "import torch\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Image as show_image\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage.measure import regionprops_table, label, regionprops\n",
    "from pycocotools import _mask as coco_mask\n",
    "import gc\n",
    "import warnings\n",
    "import torchvision.transforms as T\n",
    "import segmentation_models_pytorch as smp\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import cv2\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class model_config:\n",
    "    current_fold = 0\n",
    "    key = \"BT\" #\"MoCoV2\"\n",
    "    pretrained_resnet = False\n",
    "    seed = 42\n",
    "    train_batch_size = 8\n",
    "    valid_batch_size = 1\n",
    "    epochs = 200  # ~15 minutes per epoch\n",
    "    learning_rate = 0.0014 # 0.001 for bs=16\n",
    "    scheduler = \"CosineAnnealingLR\"\n",
    "    num_training_samples = 5499\n",
    "    T_max = int(\n",
    "        num_training_samples / train_batch_size * epochs)  # number of iterations for a full cycle, need to change for different # of iterations. (iteration = batch size)\n",
    "    weight_decay = 1e-6  # explore different weight decay (Adam optimizer)\n",
    "    n_accumulate = 1\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    iters_to_accumulate = max(1, 32 // train_batch_size)  # for scaling accumulated gradients\n",
    "    eta_min = 1e-5\n",
    "    model_save_directory = os.path.join(os.getcwd(), \"model\",\n",
    "                                        \"seresnext_attention_dropout_dilation_v2_retry\")\n",
    "\n",
    "# sets the seed of the entire notebook so results are the same every time we run for reproducibility. no randomness, everything is controlled.\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)  #numpy specific random\n",
    "    random.seed(seed)  # python specific random (also for albumentation augmentations)\n",
    "    torch.manual_seed(seed)  # torch specific random\n",
    "    torch.cuda.manual_seed(seed)  # cuda specific random\n",
    "    # when running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  # when deterministic = true, benchmark = False, otherwise might not be deterministic\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # set a fixed value for the hash seed, for hases like dictionary\n",
    "\n",
    "set_seed(model_config.seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "class HubmapDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs, transforms):\n",
    "        self.transforms = transforms\n",
    "        self.imgs = imgs\n",
    "        self.name_indices = [os.path.splitext(os.path.basename(i))[0] for i in imgs]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        img_path = self.imgs[idx]\n",
    "        name = self.name_indices[idx]\n",
    "        img=tiff.imread(img_path)\n",
    "        # array = tiff.imread(img_path)\n",
    "        # img = Image.fromarray(array)\n",
    "        img = self.transforms(image=img)\n",
    "        img = img['image']\n",
    "        return img, name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "['\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\train_overlap\\\\images\\\\5631a47d5b0c.tif']"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "debug = True\n",
    "model_path = r\"C:\\Users\\Kevin\\PycharmProjects\\hubmap\\unet++_resnet50\\model\\seresnext_attention_dropout_dilation_v3\\best_epoch-00.pt\"\n",
    "base_dir = Path('/kaggle/input/hubmap-hacking-the-human-vasculature')\n",
    "image_paths = r\"\\\\fatherserverdw\\Kevin\\hubmap\\train_overlap\\images\"\n",
    "# test_paths = [os.path.join(image_paths,x) for x in os.listdir(image_paths) if x.endswith(\".tif\")][0:10] #load all train and debug or do just first hundreds\n",
    "test_paths = [r\"\\\\fatherserverdw\\Kevin\\hubmap\\train_overlap\\images\\5631a47d5b0c.tif\"]\n",
    "test_paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "test_transforms = A.Compose([ToTensorV2()]) # Size C x H x W tensor with float dtype\n",
    "\n",
    "dataset_test = HubmapDataset(test_paths, transforms = test_transforms)\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = smp.UnetPlusPlus(encoder_name=\"se_resnext101_32x4d\", encoder_weights=None, encoder_depth = 5, decoder_channels = [512, 256, 128, 64, 32], activation='sigmoid',\n",
    "                             in_channels=3, classes=1, decoder_attention_type=\"scse\", decoder_use_batchnorm=True,\n",
    "                             aux_params={\"classes\": 1, \"pooling\": \"max\", \"dropout\": 0.5})\n",
    "    model.to(device)  # model to gpu\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max of prob prediction is 1.0\n",
      "mean of prob prediction is 0.010033367201685905\n",
      "min of prob prediction is: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "id_list, heights, widths, prediction_strings = [],[],[],[]\n",
    "with torch.no_grad():\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    for img, idx in tqdm(test_dl):\n",
    "        model.eval() #eval stage\n",
    "        img = img.to(device,dtype= torch.float32)\n",
    "        prediction, _  = model(img)\n",
    "        prediction = torch.squeeze(prediction)\n",
    "#         print(\"prob_prediction is {}\".format(prob_prediction))\n",
    "        print(\"max of prob prediction is {}\".format(torch.max(prediction)))\n",
    "        print(\"mean of prob prediction is {}\".format(torch.mean(prediction)))\n",
    "        print(\"min of prob prediction is: {}\".format(torch.min(prediction)))\n",
    "        binary_prediction = prediction > 0.000001\n",
    "        binary_prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1a75ca5df00>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa4AAAGiCAYAAAC/NyLhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAl70lEQVR4nO3deXRUZYL38V8llQSSUBW2VBEhGhXFsKkBQrlMd0skYrRdsF+aw6u0w5GRTnhlkW5pEVu754TBGRdsln7VIc640NLTuNCCZoJEbcJiJMoiEW00UagE5aQKULI+7x++1FiKaEKliif5fs6555B7n3vruU9z/HYlt4LDGGMEAIAl4mI9AQAA2oNwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsErNwLV26VGeddZZ69Oih3Nxcbd26NVZTAQBYJCbh+tOf/qQ5c+bo3nvv1dtvv62RI0cqPz9f9fX1sZgOAMAijlj8kt3c3FyNHj1af/jDHyRJbW1tGjRokGbOnKm77ror2tMBAFjEGe0XbGpqUmVlpebPnx/aFxcXp7y8PFVUVJzwnMbGRjU2Noa+bmtr06FDh9S3b185HI5OnzMAILKMMTp8+LAyMjIUF9e+b/5FPVyfffaZWltb5fF4wvZ7PB7t2bPnhOcUFxfrvvvui8b0AABRVFtbq4EDB7brnKiHqyPmz5+vOXPmhL4OBALKzMzUZbpaTiXEcGYAgI7ouSZV6254Wr169Wr3uVEPV79+/RQfH6+6urqw/XV1dfJ6vSc8JykpSUlJSd/a71SCnA7CBQC2SUhJlKQO/bgn6k8VJiYmKicnR2VlZaF9bW1tKisrk8/ni/Z0AACWicm3CufMmaOpU6dq1KhRGjNmjB5++GEdPXpUt956ayymAwCwSEzCNWnSJB08eFALFy6U3+/XhRdeqPXr13/rgQ0AAL4pZg9nFBUVqaioKFYvDwCwFL+rEABgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFAIi6ukeyOnwu4QIARF3Pv1Z2+FzCBQCwCuECAFiFcAEArEK4AABWIVwAAKsQLgCAVQgXAMAqhAsAYBXCBQCwCuECAFiFcAEArEK4AABWIVwAAKsQLgCAVQgXAMAqhAsAYBXCBQCwCuECAFiFcAEArEK4AABWIVwAAKsQLgCAVQgXAMAqhAsAYBXCBQCwCuECAFiFcAEArEK4AABWIVwAAKsQLgCAVQgXAMAqhAsAYBXCBQCwCuECAFiFcAEArEK4AABWIVwAAKsQLgCAVQgXAMAqhAsAYBXCBQCwCuECAFiFcAEArEK4AABWIVwAAKsQLgCAVQgXAMAqhAsAYBXCBQCwCuECAFil3eF6/fXXde211yojI0MOh0PPP/982HFjjBYuXKgBAwaoZ8+eysvL0969e8PGHDp0SFOmTJHL5VJaWpqmTZumI0eOnNKNAAC6h3aH6+jRoxo5cqSWLl16wuOLFy/WkiVLtGLFCm3ZskUpKSnKz8/XsWPHQmOmTJmiXbt2qbS0VGvXrtXrr7+u6dOnd/wuAADdhsMYYzp8ssOhNWvW6Prrr5f01butjIwMzZ07V3feeackKRAIyOPxqKSkRD//+c/13nvvKTs7W9u2bdOoUaMkSevXr9fVV1+tTz75RBkZGd/7usFgUG63Wz/WdXI6Ejo6fQBAjLSYZm3UCwoEAnK5XO06N6I/49q3b5/8fr/y8vJC+9xut3Jzc1VRUSFJqqioUFpaWihakpSXl6e4uDht2bLlhNdtbGxUMBgM2wAA3VNEw+X3+yVJHo8nbL/H4wkd8/v9Sk9PDzvudDrVp0+f0JhvKi4ultvtDm2DBg2K5LQBABax4qnC+fPnKxAIhLba2tpYTwkAECMRDZfX65Uk1dXVhe2vq6sLHfN6vaqvrw873tLSokOHDoXGfFNSUpJcLlfYBgDoniIarqysLHm9XpWVlYX2BYNBbdmyRT6fT5Lk8/nU0NCgysrK0JgNGzaora1Nubm5kZwOAKALcrb3hCNHjuiDDz4Ifb1v3z5VVVWpT58+yszM1KxZs/T73/9egwcPVlZWlu655x5lZGSEnjy84IILdNVVV+m2227TihUr1NzcrKKiIv385z//QU8UAgC6t3aH66233tJPfvKT0Ndz5syRJE2dOlUlJSX61a9+paNHj2r69OlqaGjQZZddpvXr16tHjx6hc55++mkVFRVp3LhxiouL08SJE7VkyZII3A4AoKs7pc9xxQqf4wIAu502n+MCAKCzES4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsEq7wlVcXKzRo0erV69eSk9P1/XXX6/q6uqwMceOHVNhYaH69u2r1NRUTZw4UXV1dWFjampqVFBQoOTkZKWnp2vevHlqaWk59bsBAHR57QpXeXm5CgsLtXnzZpWWlqq5uVnjx4/X0aNHQ2Nmz56tl156SatXr1Z5ebn279+vG2+8MXS8tbVVBQUFampq0qZNm/Tkk0+qpKRECxcujNxdAQC6LIcxxnT05IMHDyo9PV3l5eX6h3/4BwUCAfXv31/PPPOMbrrpJknSnj17dMEFF6iiokJjx47VunXrdM0112j//v3yeDySpBUrVujXv/61Dh48qMTExO993WAwKLfbrR/rOjkdCR2dPgAgRlpMszbqBQUCAblcrnade0o/4woEApKkPn36SJIqKyvV3NysvLy80JghQ4YoMzNTFRUVkqSKigoNHz48FC1Jys/PVzAY1K5du074Oo2NjQoGg2EbAKB76nC42traNGvWLF166aUaNmyYJMnv9ysxMVFpaWlhYz0ej/x+f2jM16N1/PjxYydSXFwst9sd2gYNGtTRaQMALNfhcBUWFmrnzp1atWpVJOdzQvPnz1cgEAhttbW1nf6aAIDTk7MjJxUVFWnt2rV6/fXXNXDgwNB+r9erpqYmNTQ0hL3rqqurk9frDY3ZunVr2PWOP3V4fMw3JSUlKSkpqSNTBQB0Me16x2WMUVFRkdasWaMNGzYoKysr7HhOTo4SEhJUVlYW2lddXa2amhr5fD5Jks/n044dO1RfXx8aU1paKpfLpezs7FO5FwBAN9Cud1yFhYV65pln9MILL6hXr16hn0m53W717NlTbrdb06ZN05w5c9SnTx+5XC7NnDlTPp9PY8eOlSSNHz9e2dnZuvnmm7V48WL5/X4tWLBAhYWFvKsCAHyvdj0O73A4Trh/5cqV+sUvfiHpqw8gz507V88++6waGxuVn5+vZcuWhX0b8OOPP9aMGTO0ceNGpaSkaOrUqVq0aJGczh/WUR6HBwC7ncrj8Kf0Oa5YIVwAYLeYfY4LAIBoI1wAAKsQLgCAVQgXAMAqhAsAYBXCBQCwCuECAFiFcAEArEK4AABWIVwAAKsQLgCAVQgXAMAqhAsAYBXCBQCwCuECAFiFcAEArEK4AABWIVwAAKsQLgCAVQgXAMAqhAsAYBXCBQCwCuECAFiFcAEArEK4AABWIVwAAKsQLgCAVQgXAMAqhAsAYBXCBQCwCuECAFiFcAEArEK4AABWIVwAAKsQLgCAVQgXAMAqhAsAYBXCBQCwCuECAFiFcAEArEK4AABWIVwAAKsQLgCAVZyxngAAdAfx52bps0u9+v09j4ft//3cW5W8/0vF7a1Ra0MgRrOzC+ECgE4Un+bW32cP1f++YYMW9FvzrePjl/9fSdI5G27V4Ft3yTQ3RXuK1uFbhQDQiWpXnqE9ty3Tgn57Tjru/Z88oeoVI+Rw8n7i+xAuAOgkjouG6p+HPf+DxsY74vT+VX/UR/eM6dxJdQGECwA6geOioRq18l39NOWLH3xOgiNel1/1jpxZZ3bizOxHuACgExwc49Lv03e0+7zHBv1NwQu9nTCjroNwAUCExSUna92Cf+3w+Yv+bXkEZ9P1EC4AiLT4+FM6PTvhmGrvviRCk+l6CBcARFjDc+lKj0/p8Pm945PluJjPdH0XwgUAEdSUP0ozsspP+TqTB1fK+EZGYEZdD+ECgAjy+xJ1i+uzU77Ogn57dODSFMnhiMCsuhbCBQAREt+7tzT0cMSut2XWw3JmDIjY9boKwgUAEdJ2zhl679L/jNj1Ehyn9pBHV0W4AABWIVwAAKsQLgA4TcWJBzNOhHABwGmqTSbWUzgtES4AgFUIFwDAKu0K1/LlyzVixAi5XC65XC75fD6tW7cudPzYsWMqLCxU3759lZqaqokTJ6quri7sGjU1NSooKFBycrLS09M1b948tbS0ROZuAABdXrvCNXDgQC1atEiVlZV66623dMUVV+i6667Trl27JEmzZ8/WSy+9pNWrV6u8vFz79+/XjTfeGDq/tbVVBQUFampq0qZNm/Tkk0+qpKRECxcujOxdAQC6LIcx5pR++tenTx898MADuummm9S/f38988wzuummmyRJe/bs0QUXXKCKigqNHTtW69at0zXXXKP9+/fL4/FIklasWKFf//rXOnjwoBITE3/QawaDQbndbv1Y18npSDiV6QNAxDhGDdP6F5+K2PWaTauuH3OtWj7dH7Frni5aTLM26gUFAgG5XK52ndvhn3G1trZq1apVOnr0qHw+nyorK9Xc3Ky8vLzQmCFDhigzM1MVFRWSpIqKCg0fPjwULUnKz89XMBgMvWs7kcbGRgWDwbANANA9tTtcO3bsUGpqqpKSknT77bdrzZo1ys7Olt/vV2JiotLS0sLGezwe+f1+SZLf7w+L1vHjx499l+LiYrnd7tA2aNCg9k4bAKxzwapCtdaf+i/s7WraHa7zzz9fVVVV2rJli2bMmKGpU6dq9+7dnTG3kPnz5ysQCIS22traTn09AIi1v37RQ2e81ibT3BTrqZx2nO09ITExUeeee64kKScnR9u2bdMjjzyiSZMmqampSQ0NDWHvuurq6uT1eiVJXq9XW7duDbve8acOj485kaSkJCUlJbV3qgBgrV+9M1ED1279/oHd0Cl/jqutrU2NjY3KyclRQkKCysrKQseqq6tVU1Mjn88nSfL5fNqxY4fq6+tDY0pLS+VyuZSdnX2qUwGALqGysUln3dEQ62mcttr1jmv+/PmaMGGCMjMzdfjwYT3zzDPauHGjXnnlFbndbk2bNk1z5sxRnz595HK5NHPmTPl8Po0dO1aSNH78eGVnZ+vmm2/W4sWL5ff7tWDBAhUWFvKOCoD14g8GdFvtpXps0N9O6TqTKqbrnE+qIjOpLqhd4aqvr9ctt9yiAwcOyO12a8SIEXrllVd05ZVXSpIeeughxcXFaeLEiWpsbFR+fr6WLVsWOj8+Pl5r167VjBkz5PP5lJKSoqlTp+r++++P7F0BQAy0fFyrN9ddIk3veLgaTbPOfpTfUXgyp/w5rljgc1wATlc1v71E701f9v0DT+C9pi80+cE75Xm0QrLvP83tEpPPcQEAvi3jjUY9Efjuh81O5p/3Xy3Pkk1dPlqninABQAQ5yyr1Uv3Idp+3+VirDs7iM6o/RLsfhwcARNaKhjP0X9OvVNzWqlhPxQq84wKACDu4NEuBti+/d1yradPGL+O0uugqxb1Z1fkT6yIIFwBEmOvFKq0MXHDSMe83H9XFDxTpgUuvlHNDZZRm1jUQLgCIsLZjx/Tne/O/8/iwzVM06YF58j68SS3+uu8chxPjZ1wA0Alc5X/X0IopWjvqj6F9JQ252nj3pcqs+ECtn3/3v4iBkyNcANAJWg8e1MCfHdKMhHH/s7PNqEfzVrXGblpdAuECgM7S1irTSKYijZ9xAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVTilcixYtksPh0KxZs0L7jh07psLCQvXt21epqamaOHGi6urqws6rqalRQUGBkpOTlZ6ernnz5qmlpeVUpgIAsIjzjAEdPrfD4dq2bZv++Mc/asSIEWH7Z8+erZdeekmrV69WeXm59u/frxtvvDF0vLW1VQUFBWpqatKmTZv05JNPqqSkRAsXLuzwTQAA7JK8srHD53YoXEeOHNGUKVP02GOPqXfv3qH9gUBATzzxhB588EFdccUVysnJ0cqVK7Vp0yZt3rxZkvTqq69q9+7deuqpp3ThhRdqwoQJ+t3vfqelS5eqqampwzcCAOgeOhSuwsJCFRQUKC8vL2x/ZWWlmpubw/YPGTJEmZmZqqiokCRVVFRo+PDh8ng8oTH5+fkKBoPatWvXCV+vsbFRwWAwbAMAdE/O9p6watUqvf3229q2bdu3jvn9fiUmJiotLS1sv8fjkd/vD435erSOHz9+7ESKi4t13333tXeqAIAuqF3vuGpra3XHHXfo6aefVo8ePTprTt8yf/58BQKB0FZbWxu11wYAnF7aFa7KykrV19fr4osvltPplNPpVHl5uZYsWSKn0ymPx6OmpiY1NDSEnVdXVyev1ytJ8nq933rK8PjXx8d8U1JSklwuV9gGAOie2hWucePGaceOHaqqqgpto0aN0pQpU0J/TkhIUFlZWeic6upq1dTUyOfzSZJ8Pp927Nih+vr60JjS0lK5XC5lZ2dH6LYAAF1Vu37G1atXLw0bNixsX0pKivr27RvaP23aNM2ZM0d9+vSRy+XSzJkz5fP5NHbsWEnS+PHjlZ2drZtvvlmLFy+W3+/XggULVFhYqKSkpAjdFgCgq2r3wxnf56GHHlJcXJwmTpyoxsZG5efna9myZaHj8fHxWrt2rWbMmCGfz6eUlBRNnTpV999/f6SnAgDoghzGGBPrSbRXMBiU2+3Wj3WdnI6EWE8HANBOya/00ovjVyoQCLT7uQV+VyEAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAIOp2//fgDp9LuAAAUTdw8ZYOn0u4AABWIVwAAKsQLgCAVQgXAMAqhAsAYBXCBQCwijPWEwCA7qbu/1yioxlGZ607prjy7bGejnUIFwBESduPLtJZi9/XCu9iZSWk6j+u76c3AueHjpdVn6/zbtsl09gYw1me/ggXAERBy7gc/eGJR3VBYrKkVEnSLa7PdIvrs9CY1oFvKPs/fqG+f0lWrz9tjtFMT3+ECwA6WdNVo3Xrw2v+f7S+W7wjTtWX/4fqLzkq3zVFOmtlnJwbKqM0S3vwcAYAdCLnmYP0L8uXhb2z+j7p8Sn6cNxK3f/4Y2r70UVyej2dOEP7EC4A6EQmwakxSQkdOvfSHnEqfXalEv4kObPOjPDM7EW4AOA09/zgV5Tyn0cU16NHrKdyWiBcAGCB584uU6//TuGdlwgXAFjjubPLlFByrNv/zItwAUAnavv4U537zO0Ru97zg1+R6ZsWsevZiHABQCcyzU1K+TSy/6mtndA3otezDeECgM5mInu5u297NrIXtAzhAoBOlvHYO/rJrusidr20+C8Uf25WxK5nG8IFAJ2s7ehRNbxwhj5rPRqR612V3Kg99/SOyLVsRLgAIArS/7BJVzw0L2LXe+yyJ9V01eiIXc8mhAsAouSMDQ16IuCNyLXG9WxV7ZXxcji736+cJVwAECVtVbv19MwCPXfEHZHrVU56SHGpKRG5lk0IFwBEUcJ/V+rN4HkRuZY7rqe+eK634vt1r8fjCRcARNm6DaPUatoicq2Nw57XB3dGJoS2IFwAEGWDF7+vRtMSsevd8dO1iht5QcSud7ojXAAQA/EOR8SuVZhWq9n/9Wc5coZG7JqnM8IFAFFmvvhSo7fdEtFrjk9u1vgnK9R2+UURve7piHABQJS1ffGFkl5Mi/h15/T5u2574i+KH3p+xK99OiFcANCF/K/UgC559p1YT6NTES4A6GJucG3X57f5Yj2NTkO4ACAG+q16RyO2Tu6Uaw9N7Knn73lAn/1T14wX4QKAGDDnZ+nKQdWddv2BzlRtuOdBfTa968WLcAFADHx+kUv/NuDtTn0Nd1xPPTH/4a/eeUXw8ftYI1wA0IVdmJSkN+55RJ9NHxvrqURMu8L129/+Vg6HI2wbMmRI6PixY8dUWFiovn37KjU1VRMnTlRdXV3YNWpqalRQUKDk5GSlp6dr3rx5ammJ3CfIAcAG/SobVPRpblReKzkuUc/95oEu88BGu99xDR06VAcOHAhtb775ZujY7Nmz9dJLL2n16tUqLy/X/v37deONN4aOt7a2qqCgQE1NTdq0aZOefPJJlZSUaOHChZG5GwCwRNs77+mVvdH7NU3nJKTqmQX/qi9ujE4sO1O7w+V0OuX1ekNbv379JEmBQEBPPPGEHnzwQV1xxRXKycnRypUrtWnTJm3evFmS9Oqrr2r37t166qmndOGFF2rChAn63e9+p6VLl6qpqSmydwYAp7mUimTVtByJ2uudl5CiT3/aIkdSUtReszO0O1x79+5VRkaGzj77bE2ZMkU1NTWSpMrKSjU3NysvLy80dsiQIcrMzFRFRYUkqaKiQsOHD5fH4wmNyc/PVzAY1K5du77zNRsbGxUMBsM2ALCd59FNuvahX6nZtEbtNd/NW6q4tMj8e2Cx0q5w5ebmqqSkROvXr9fy5cu1b98+XX755Tp8+LD8fr8SExOVlpYWdo7H45Hf75ck+f3+sGgdP3782HcpLi6W2+0ObYMGDWrPtAHgtOV9ZItG/8tMzT1wcVQClhrXQz1Wm05/nc7UrnBNmDBBP/vZzzRixAjl5+fr5ZdfVkNDg5577rnOmp8kaf78+QoEAqGttra2U18PAKKmrVWeJZu0KzdOQ/+zSL/8tPOf/uvfI3rfnuwMp/Q4fFpams477zx98MEH8nq9ampqUkNDQ9iYuro6eb1eSZLX6/3WU4bHvz4+5kSSkpLkcrnCNgDoSkxLi7LuqtBHU87QpXf8U6f+7Otub6n8sy/ptOt3tlMK15EjR/Thhx9qwIABysnJUUJCgsrKykLHq6urVVNTI5/vq0cwfT6fduzYofr6+tCY0tJSuVwuZWdnn8pUAKBLaH3/Q6Wu3qIpd8zVmO0/U6Dty4i/RqYzVV947P12YbvCdeedd6q8vFwfffSRNm3apBtuuEHx8fGaPHmy3G63pk2bpjlz5ui1115TZWWlbr31Vvl8Po0d+9Vb3/Hjxys7O1s333yz3nnnHb3yyitasGCBCgsLlWT5Uy4AEEnJa7aod8FejX5qTsSvXRJM11lrIx/EaHG2Z/Ann3yiyZMn6/PPP1f//v112WWXafPmzerfv78k6aGHHlJcXJwmTpyoxsZG5efna9myZaHz4+PjtXbtWs2YMUM+n08pKSmaOnWq7r///sjeFQB0EVl/OaKtk5o1JikhYtesCJ6juDerIna9aHMYY6x7vxgMBuV2u/VjXSenI3L/YwLA6ejoTbm6718e17iep/7UYbNp1fDHZ+rMezdFYGYd12KatVEvKBAItPu5hXa94zpdHG9ti5ol67ILAO2TtPpNPVs4UqMz3jrla7Uao2OeBrWY5gjMrONa9NXrd+S9k5XvuP7+97/rnHPOifU0AACnqLa2VgMHDmzXOVa+4+rTp4+kr35hr9tt9yfAO0swGNSgQYNUW1vLxwdOgPU5Odbn5Fifk/sh62OM0eHDh5WRkdHu61sZrri4rx6GdLvd/KX5Hnzu7eRYn5NjfU6O9Tm571ufjr7x4N/jAgBYhXABAKxiZbiSkpJ077338qHlk2CNTo71OTnW5+RYn5Pr7PWx8qlCAED3ZeU7LgBA90W4AABWIVwAAKsQLgCAVawM19KlS3XWWWepR48eys3N1datW2M9pah4/fXXde211yojI0MOh0PPP/982HFjjBYuXKgBAwaoZ8+eysvL0969e8PGHDp0SFOmTJHL5VJaWpqmTZumI0fs/tdQjysuLtbo0aPVq1cvpaen6/rrr1d1dXXYmGPHjqmwsFB9+/ZVamqqJk6c+K1/3LSmpkYFBQVKTk5Wenq65s2bp5aWlmjeSqdYvny5RowYEfpQqM/n07p160LHu/PanMiiRYvkcDg0a9as0L7uvEa//e1v5XA4wrYhQ4aEjkd1bYxlVq1aZRITE82///u/m127dpnbbrvNpKWlmbq6ulhPrdO9/PLL5u677zZ/+ctfjCSzZs2asOOLFi0ybrfbPP/88+add94xP/3pT01WVpb58ssvQ2OuuuoqM3LkSLN582bzxhtvmHPPPddMnjw5ynfSOfLz883KlSvNzp07TVVVlbn66qtNZmamOXLkSGjM7bffbgYNGmTKysrMW2+9ZcaOHWsuueSS0PGWlhYzbNgwk5eXZ7Zv325efvll069fPzN//vxY3FJEvfjii+avf/2ref/99011dbX5zW9+YxISEszOnTuNMd17bb5p69at5qyzzjIjRowwd9xxR2h/d16je++91wwdOtQcOHAgtB08eDB0PJprY124xowZYwoLC0Nft7a2moyMDFNcXBzDWUXfN8PV1tZmvF6veeCBB0L7GhoaTFJSknn22WeNMcbs3r3bSDLbtm0LjVm3bp1xOBzm008/jdrco6W+vt5IMuXl5caYr9YjISHBrF69OjTmvffeM5JMRUWFMear/3MQFxdn/H5/aMzy5cuNy+UyjY2N0b2BKOjdu7d5/PHHWZuvOXz4sBk8eLApLS01P/rRj0Lh6u5rdO+995qRI0ee8Fi018aqbxU2NTWpsrJSeXl5oX1xcXHKy8tTRUVFDGcWe/v27ZPf7w9bG7fbrdzc3NDaVFRUKC0tTaNGjQqNycvLU1xcnLZs2RL1OXe2QCAg6X9+KXNlZaWam5vD1mjIkCHKzMwMW6Phw4fL4/GExuTn5ysYDGrXrl1RnH3nam1t1apVq3T06FH5fD7W5msKCwtVUFAQthYSf38kae/evcrIyNDZZ5+tKVOmqKamRlL018aqX7L72WefqbW1NezGJcnj8WjPnj0xmtXpwe/3S9IJ1+b4Mb/fr/T09LDjTqdTffr0CY3pKtra2jRr1ixdeumlGjZsmKSv7j8xMVFpaWlhY7+5Ridaw+PHbLdjxw75fD4dO3ZMqampWrNmjbKzs1VVVdXt10aSVq1apbffflvbtm371rHu/vcnNzdXJSUlOv/883XgwAHdd999uvzyy7Vz586or41V4QJ+qMLCQu3cuVNvvvlmrKdyWjn//PNVVVWlQCCgP//5z5o6darKy8tjPa3TQm1tre644w6VlpaqR48esZ7OaWfChAmhP48YMUK5ubk688wz9dxzz6lnz55RnYtV3yrs16+f4uPjv/WkSl1dnbxeb4xmdXo4fv8nWxuv16v6+vqw4y0tLTp06FCXWr+ioiKtXbtWr732Wtg/UOf1etXU1KSGhoaw8d9coxOt4fFjtktMTNS5556rnJwcFRcXa+TIkXrkkUdYG3317a76+npdfPHFcjqdcjqdKi8v15IlS+R0OuXxeLr9Gn1dWlqazjvvPH3wwQdR//tjVbgSExOVk5OjsrKy0L62tjaVlZXJ5/PFcGaxl5WVJa/XG7Y2wWBQW7ZsCa2Nz+dTQ0ODKisrQ2M2bNigtrY25ebmRn3OkWaMUVFRkdasWaMNGzYoKysr7HhOTo4SEhLC1qi6ulo1NTVha7Rjx46wwJeWlsrlcik7Ozs6NxJFbW1tamxsZG0kjRs3Tjt27FBVVVVoGzVqlKZMmRL6c3dfo687cuSIPvzwQw0YMCD6f3/a/WhJjK1atcokJSWZkpISs3v3bjN9+nSTlpYW9qRKV3X48GGzfft2s337diPJPPjgg2b79u3m448/NsZ89Th8WlqaeeGFF8y7775rrrvuuhM+Dn/RRReZLVu2mDfffNMMHjy4yzwOP2PGDON2u83GjRvDHtn94osvQmNuv/12k5mZaTZs2GDeeust4/P5jM/nCx0//sju+PHjTVVVlVm/fr3p379/l3ic+a677jLl5eVm37595t133zV33XWXcTgc5tVXXzXGdO+1+S5ff6rQmO69RnPnzjUbN240+/btM3/7299MXl6e6devn6mvrzfGRHdtrAuXMcY8+uijJjMz0yQmJpoxY8aYzZs3x3pKUfHaa68ZSd/apk6daoz56pH4e+65x3g8HpOUlGTGjRtnqqurw67x+eefm8mTJ5vU1FTjcrnMrbfeag4fPhyDu4m8E62NJLNy5crQmC+//NL88pe/NL179zbJycnmhhtuMAcOHAi7zkcffWQmTJhgevbsafr162fmzp1rmpubo3w3kfeP//iP5swzzzSJiYmmf//+Zty4caFoGdO91+a7fDNc3XmNJk2aZAYMGGASExPNGWecYSZNmmQ++OCD0PForg3/rAkAwCpW/YwLAADCBQCwCuECAFiFcAEArEK4AABWIVwAAKsQLgCAVQgXAMAqhAsAYBXCBQCwCuECAFiFcAEArPL/AKswEu6OKDwUAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "binary_prediction_cpu = binary_prediction.cpu().numpy()\n",
    "plt.imshow(binary_prediction_cpu)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "### Irrelevant code to see how much bv is in the image:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_total_relative_area(file_path):\n",
    "    # Get all .tif file paths in the specified directory\n",
    "    file_paths = [os.path.join(file_path, file) for file in os.listdir(file_path) if file.endswith('.tif')]\n",
    "\n",
    "    total_area = 0\n",
    "\n",
    "    for file_path in tqdm(file_paths):\n",
    "        # Load the image using PIL\n",
    "        image = Image.open(file_path)\n",
    "\n",
    "        # Convert the image to a numpy array\n",
    "        binary_mask = np.array(image)\n",
    "\n",
    "        # Calculate the total number of labels (ones) in the binary mask\n",
    "        num_labels = np.sum(binary_mask == 1)\n",
    "\n",
    "        # Calculate the total relative area of the labels\n",
    "        relative_area = num_labels / (512 * 512)\n",
    "\n",
    "        # Accumulate the relative area across all images\n",
    "        total_area += relative_area\n",
    "\n",
    "    return total_area\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6874/6874 [01:21<00:00, 84.14it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": "351.7162437438965"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_total_relative_area(r\"\\\\fatherserverdw\\Kevin\\hubmap\\train_overlap\\masks\\blood_vessel\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "0.051163805644457376"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "351.7/6874"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def remove_rows_by_names_from_excel(excel_file_path, names_to_remove):\n",
    "    try:\n",
    "        # Read the Excel file into a DataFrame\n",
    "        df = pd.read_excel(excel_file_path)\n",
    "\n",
    "        # Remove rows that contain any of the names from the list\n",
    "        df = df[~df['Column_Name'].str.contains('|'.join(names_to_remove))]\n",
    "\n",
    "        # Save the updated DataFrame back to the Excel file\n",
    "        df.to_excel(excel_file_path, index=False)\n",
    "        print(\"Rows with specified names have been removed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while processing the Excel file: {e}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Replace 'your_excel_file_path' with the path to your Excel file\n",
    "excel_file_path = r\"\\\\fatherserverdw\\Kevin\\hubmap\\unet++_v2\\train_fold1.xlsx\"\n",
    "names_list = ['458a92eda7b4_bot_right.tif',\n",
    " '214866956ea3_top_right.tif',\n",
    " '4c1361e4c2d8_bot_left.tif',\n",
    " '578c8b32057e_top_left.tif',\n",
    " 'cbc4758c8c53_bot_right.tif',\n",
    " '936f9bfb3966_top_right.tif',\n",
    " 'e5ac1caaadd8_bot_left.tif',\n",
    " '27ac6c438f3b_top_left.tif',\n",
    " '97f404585e68_bot_right.tif',\n",
    " 'aef16812206a_top_right.tif',\n",
    " '8cb7d2ef7d2c_bot_left.tif',\n",
    " '7aeb05949f93_top_left.tif',\n",
    " '7aeb05949f93_bot_right.tif',\n",
    " '76a3142ef6ee_top_right.tif',\n",
    " '3fc432760114_bot_left.tif',\n",
    " 'cfcbc3b1aa48_top_left.tif',\n",
    " '2b1cf5bbc9ea_bot_right.tif',\n",
    " '9d3653466f61_top_right.tif',\n",
    " '5e8476b465f9_bot_left.tif',\n",
    " 'e8758c97b189_top_left.tif',\n",
    " '89184912fef8_bot_right.tif',\n",
    " '4dae128831ab_top_right.tif',\n",
    " 'dcd2a14a9980_bot_left.tif',\n",
    " '93c7422d2878_top_left.tif',\n",
    " '3dee55fb6fcc_bot_right.tif',\n",
    " '22db9740ba20_top_right.tif',\n",
    " '590f64bf82a6_bot_left.tif',\n",
    " 'b3ee5e7bcf74_top_left.tif'] # Replace this list with the one returned by the previous function\n",
    "remove_rows_by_names_from_excel(excel_file_path, names_list)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
