{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "If your goal is to only detect class A, and you have limited labeled data for class A compared to the unlabeled data, a semi-supervised learning approach can be beneficial. Here's a suggested approach using semi-supervised learning in your scenario:\n",
    "\n",
    "Labeled Data for Class A: Utilize the available labeled data for class A to train a YOLOv8 model initially. This labeled dataset provides the ground truth annotations for class A instances, allowing the model to learn from the labeled examples. However, the limited amount of labeled data may result in suboptimal performance.\n",
    "\n",
    "Self-Supervised Pretraining: As you mentioned, you have a larger unlabeled dataset. You can leverage this unlabeled data to train a self-supervised model using one of the methods discussed earlier (e.g., instance discrimination, context prediction, or contrastive learning). This self-supervised model will learn to extract useful features and representations from the unlabeled data.\n",
    "\n",
    "Pretraining the Initial Layers: Take the pretrained weights from the self-supervised model and use them to initialize the initial layers of your YOLOv8 model. By doing so, you provide the YOLOv8 model with pretrained representations that capture meaningful information from the unlabeled data.\n",
    "\n",
    "Semi-Supervised Training: After initializing the initial layers, fine-tune the YOLOv8 model using a combination of the limited labeled data for class A and the unlabeled data. You can employ semi-supervised learning techniques, such as consistency regularization or pseudo-labeling, to utilize the unlabeled data effectively.\n",
    "\n",
    "Consistency Regularization: Apply consistency regularization to encourage the model to produce consistent predictions on different augmentations or transformations of the same unlabeled sample. This helps the model to learn more robust and generalizable representations, even in the absence of labeled data for class A.\n",
    "\n",
    "Pseudo-labeling: Pseudo-labeling can also be employed, where the model's predictions on the unlabeled data are used as pseudo-labels for training. This allows you to utilize the unlabeled data effectively and expand the labeled dataset, thereby improving the model's performance.\n",
    "\n",
    "By combining the limited labeled data for class A with the larger unlabeled dataset and leveraging the benefits of self-supervised learning, you can improve the performance of your YOLOv8 model in detecting class A instances. The self-supervised pretraining helps to capture useful representations from the unlabeled data, while the semi-supervised training enables the model to learn from both labeled and unlabeled data, enhancing its ability to generalize.\n",
    "\n",
    "Remember to validate and fine-tune the model's hyperparameters and settings based on the performance on a separate validation or test set to ensure the best results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# import necessary packages:\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-04T16:49:00.076244Z",
     "end_time": "2023-06-04T16:49:00.513557Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-04T16:49:00.591683Z",
     "end_time": "2023-06-04T16:49:00.622935Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# flags and directories for data and csv:\n",
    "kaggle_env = False\n",
    "if kaggle_env:\n",
    "    data_directory = \"/kaggle/input/hubmap-hacking-the-human-vasculature\"\n",
    "if not kaggle_env:\n",
    "    #local_env = r\"C:\\Users\\labadmin\\PycharmProjects\\hubmap\" # edit local directory accordingly\n",
    "    local_env = r\"C:\\Users\\Kevin\\PycharmProjects\\hubmap\"\n",
    "    #data_directory = r\"C:\\Users\\labadmin\\Desktop\\hubmap\"\n",
    "    data_directory = r\"C:\\Users\\Kevin\\Desktop\\hubmap\"\n",
    "wsi_csv_src = os.path.join(data_directory,\"wsi_meta.csv\")\n",
    "tile_csv_src = os.path.join(data_directory,\"tile_meta.csv\")\n",
    "train_tile_src = os.path.join(data_directory,\"train\")\n",
    "json_src = os.path.join(data_directory,\"polygons.jsonl\")\n",
    "wsi_df = pd.read_csv(wsi_csv_src)\n",
    "tile_df = pd.read_csv(tile_csv_src)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-04T16:49:07.482546Z",
     "end_time": "2023-06-04T16:49:07.545055Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-06-04T16:49:09.797316Z",
     "end_time": "2023-06-04T16:49:09.826451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   source_wsi  age sex race  height  weight   bmi\n0           1   58   F    W   160.0    59.0  23.0\n1           2   56   F    W   175.2   139.6  45.5\n2           3   73   F    W   162.3    87.5  33.2\n3           4   53   M    B   166.0    73.0  26.5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source_wsi</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>race</th>\n      <th>height</th>\n      <th>weight</th>\n      <th>bmi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>58</td>\n      <td>F</td>\n      <td>W</td>\n      <td>160.0</td>\n      <td>59.0</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>56</td>\n      <td>F</td>\n      <td>W</td>\n      <td>175.2</td>\n      <td>139.6</td>\n      <td>45.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>73</td>\n      <td>F</td>\n      <td>W</td>\n      <td>162.3</td>\n      <td>87.5</td>\n      <td>33.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>53</td>\n      <td>M</td>\n      <td>B</td>\n      <td>166.0</td>\n      <td>73.0</td>\n      <td>26.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IMPORTANT EDA CONCLUSIONS (from: https://www.kaggle.com/code/leonidkulyk/eda-hubmap-hhv-interactive-annotations): DATASET 1 = EXPERT REVIEWED ANNOTATED DATASET, DATASET 2 EXPERT NON-REVIEWED SPARSE ANNOTATIONS, DATASET 3 NO LABELS! ALSO, THERE ARE 15 UNIQUE SOURCE_WSIS, WITH EACH WSI HAVING MOSTLY 600 ANNOTATIONS, WITH SOME HAVING 200-500."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "             id  source_wsi  dataset      i      j\n0  0006ff2aa7cd           2        2  16896  16420\n1  000e79e206b7           6        3  10240  29184\n2  00168d1b7522           2        2  14848  14884\n3  00176a88fdb0           7        3  14848  25088\n4  0033bbc76b6b           1        1  10240  43008\n5  003504460b3a           3        2   8192  11776\n6  00359ab8338b           8        3   6656   9216\n7  00488ca285ee           9        3   8192  37888\n8  004daf1cbe75           3        2   6144  11264\n9  004fb033dd09           7        3  20480  31232",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>source_wsi</th>\n      <th>dataset</th>\n      <th>i</th>\n      <th>j</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0006ff2aa7cd</td>\n      <td>2</td>\n      <td>2</td>\n      <td>16896</td>\n      <td>16420</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000e79e206b7</td>\n      <td>6</td>\n      <td>3</td>\n      <td>10240</td>\n      <td>29184</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00168d1b7522</td>\n      <td>2</td>\n      <td>2</td>\n      <td>14848</td>\n      <td>14884</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00176a88fdb0</td>\n      <td>7</td>\n      <td>3</td>\n      <td>14848</td>\n      <td>25088</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0033bbc76b6b</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10240</td>\n      <td>43008</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>003504460b3a</td>\n      <td>3</td>\n      <td>2</td>\n      <td>8192</td>\n      <td>11776</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>00359ab8338b</td>\n      <td>8</td>\n      <td>3</td>\n      <td>6656</td>\n      <td>9216</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>00488ca285ee</td>\n      <td>9</td>\n      <td>3</td>\n      <td>8192</td>\n      <td>37888</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>004daf1cbe75</td>\n      <td>3</td>\n      <td>2</td>\n      <td>6144</td>\n      <td>11264</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>004fb033dd09</td>\n      <td>7</td>\n      <td>3</td>\n      <td>20480</td>\n      <td>31232</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-04T16:49:15.154398Z",
     "end_time": "2023-06-04T16:49:15.170027Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Hubmap_dataset(Dataset):\n",
    "    #credits to: https://www.kaggle.com/code/alincijov/dataset-hubmap-vasc-768x768-segments\n",
    "    def __init__(self, json_path, image_dir, augments = False, train=True):\n",
    "        #read jsonl file, contains all info about the annotations\n",
    "        with open(json_path) as json_file:\n",
    "            json_list = list(json_file) #list of all jsons\n",
    "        #create new df\n",
    "        dataset = []\n",
    "        for json_str in tqdm(json_list, desc=\"Json Data Loaded\"):\n",
    "            result = json.loads(json_str)\n",
    "\n",
    "            annotations = result['annotations']\n",
    "            for ann in annotations:\n",
    "                row = {}\n",
    "                row[\"id\"] = result[\"id\"]\n",
    "                row[\"type\"] = ann[\"type\"]\n",
    "                row[\"coordinates\"] = ann[\"coordinates\"]\n",
    "                row[\"mask\"] = self.coordinates_to_masks(ann[\"coordinates\"], (512, 512))[0]\n",
    "                row[\"rle\"] = self.mask2enc(row[\"mask\"])\n",
    "                dataset.append(row)\n",
    "\n",
    "        # define dataset, to make it easier to get...\n",
    "        self.dataset = pd.DataFrame(dataset, columns=[\"id\", \"type\", \"coordinates\", \"mask\", \"rle\"])\n",
    "        self.train = train\n",
    "        self.image_dir = image_dir\n",
    "\n",
    "    def enc2mask(self, encs, shape):\n",
    "        '''\n",
    "        Function to go from input RLE encodings to mask\n",
    "        :param encs: input RLE encodings\n",
    "        :param shape: shape of output mask\n",
    "        :return:\n",
    "        '''\n",
    "        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "        for m,enc in enumerate(encs):\n",
    "            if isinstance(enc,np.float) and np.isnan(enc):\n",
    "                continue #skip nan's\n",
    "            s = enc.split()\n",
    "            for i in range(len(s)//2):\n",
    "                start = int(s[2*i]) - 1\n",
    "                length = int(s[2*i+1])\n",
    "                img[start:start+length] = 1 + m\n",
    "        return img.reshape(shape).T\n",
    "\n",
    "    def mask2enc(self, mask, n=1):\n",
    "        '''\n",
    "        Function to go from input mask to RLE encodings\n",
    "        :param mask:\n",
    "        :param n:\n",
    "        :return:\n",
    "        '''\n",
    "        pixels = mask.T.flatten()\n",
    "        encs = []\n",
    "        for i in range(1,n+1):\n",
    "            p = (pixels == i).astype(np.int8)\n",
    "            if p.sum() == 0: encs.append(np.nan)\n",
    "            else:\n",
    "                p = np.concatenate([[0], p, [0]])\n",
    "                runs = np.where(p[1:] != p[:-1])[0] + 1\n",
    "                runs[1::2] -= runs[::2]\n",
    "                encs.append(' '.join(str(x) for x in runs))\n",
    "        return encs\n",
    "\n",
    "    def coordinates_to_masks(self, coordinates, shape):\n",
    "        masks = []\n",
    "        for coord in coordinates:\n",
    "            mask = np.zeros(shape, dtype=np.uint8) #512x512 empty initialization\n",
    "            cv2.fillPoly(mask, [np.array(coord)], 1)\n",
    "            masks.append(mask)\n",
    "        return masks #return appended masks\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = self.dataset.iloc[idx]\n",
    "\n",
    "        imageLoc = os.path.join(self.image_dir,data.id+\".tif\")\n",
    "        img = cv2.imread(imageLoc)\n",
    "\n",
    "        type_struct = data.type\n",
    "        coord = data.coordinates[0]\n",
    "\n",
    "        # create mask array\n",
    "        mask = np.zeros((512, 512), dtype=np.float32)\n",
    "        points = np.array(coord)\n",
    "        points = points.reshape((1, -1, 2))\n",
    "        mask = cv2.fillPoly(mask, pts=points, color=(255))\n",
    "\n",
    "        return img, type_struct, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Json Data Loaded: 100%|██████████| 1633/1633 [00:15<00:00, 107.20it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset= Hubmap_dataset(json_path = json_src, augments=False,image_dir=train_tile_src, train=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "### AS SEEN BELOW, ID MATCHES THE ID OF THE IMAGE DATASET NAME, TYPE IS EITHER BLOOD_VESSEL(TARGET), GLOMERULUS (WE DONT WANT), AND UNSURE. MOST IMPORTANT: # OF ANNOTATED TILES IS 1633, WHILE NUMBER OF UNANNOTATED TILES IS 5400 TO MAKE IT TOTAL OF 7033 TILES IN THE IMAGES WE ARE GIVEN. NEED TO TRAIN SEMISUPERVISED MODEL!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                 id          type  \\\n0      0006ff2aa7cd    glomerulus   \n1      0006ff2aa7cd  blood_vessel   \n2      0006ff2aa7cd  blood_vessel   \n3      0006ff2aa7cd  blood_vessel   \n4      0006ff2aa7cd  blood_vessel   \n...             ...           ...   \n17513  ffd3d193c71e  blood_vessel   \n17514  ffd3d193c71e  blood_vessel   \n17515  ffd3d193c71e  blood_vessel   \n17516  ffd3d193c71e  blood_vessel   \n17517  ffd3d193c71e  blood_vessel   \n\n                                             coordinates  \\\n0      [[[167, 249], [166, 249], [165, 249], [164, 24...   \n1      [[[283, 109], [282, 109], [281, 109], [280, 10...   \n2      [[[104, 292], [103, 292], [102, 292], [101, 29...   \n3      [[[505, 442], [504, 442], [503, 442], [502, 44...   \n4      [[[375, 477], [374, 477], [373, 477], [372, 47...   \n...                                                  ...   \n17513  [[[184, 308], [183, 308], [182, 308], [181, 30...   \n17514  [[[42, 92], [41, 92], [40, 92], [39, 92], [38,...   \n17515  [[[287, 480], [286, 480], [285, 480], [284, 48...   \n17516  [[[493, 388], [492, 388], [491, 388], [490, 38...   \n17517  [[[64, 15], [63, 15], [62, 15], [61, 15], [61,...   \n\n                                                    mask  \\\n0      [[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n1      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n2      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n3      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n4      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n...                                                  ...   \n17513  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n17514  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n17515  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n17516  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n17517  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n\n                                                     rle  \n0      [2 105 513 107 1025 111 1537 113 2049 114 2561...  \n1      [139350 10 139860 17 140370 22 140880 27 14139...  \n2      [37108 4 37618 8 38129 11 38640 14 39152 15 39...  \n3      [250783 11 251292 20 251801 26 252311 30 25282...  \n4      [167352 5 167863 7 168374 10 168886 11 169398 ...  \n...                                                  ...  \n17513  [88875 8 89385 11 89896 13 90407 15 90918 16 9...  \n17514  [14393 12 14904 20 15415 23 15925 28 16434 40 ...  \n17515  [140243 6 140750 13 141261 15 141772 17 142284...  \n17516  [244001 5 244512 7 244603 6 245023 9 245112 11...  \n17517  [27652 5 28162 9 28673 12 29185 13 29697 14 30...  \n\n[17518 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>type</th>\n      <th>coordinates</th>\n      <th>mask</th>\n      <th>rle</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0006ff2aa7cd</td>\n      <td>glomerulus</td>\n      <td>[[[167, 249], [166, 249], [165, 249], [164, 24...</td>\n      <td>[[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n      <td>[2 105 513 107 1025 111 1537 113 2049 114 2561...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0006ff2aa7cd</td>\n      <td>blood_vessel</td>\n      <td>[[[283, 109], [282, 109], [281, 109], [280, 10...</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n      <td>[139350 10 139860 17 140370 22 140880 27 14139...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0006ff2aa7cd</td>\n      <td>blood_vessel</td>\n      <td>[[[104, 292], [103, 292], [102, 292], [101, 29...</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n      <td>[37108 4 37618 8 38129 11 38640 14 39152 15 39...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0006ff2aa7cd</td>\n      <td>blood_vessel</td>\n      <td>[[[505, 442], [504, 442], [503, 442], [502, 44...</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n      <td>[250783 11 251292 20 251801 26 252311 30 25282...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0006ff2aa7cd</td>\n      <td>blood_vessel</td>\n      <td>[[[375, 477], [374, 477], [373, 477], [372, 47...</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n      <td>[167352 5 167863 7 168374 10 168886 11 169398 ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17513</th>\n      <td>ffd3d193c71e</td>\n      <td>blood_vessel</td>\n      <td>[[[184, 308], [183, 308], [182, 308], [181, 30...</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n      <td>[88875 8 89385 11 89896 13 90407 15 90918 16 9...</td>\n    </tr>\n    <tr>\n      <th>17514</th>\n      <td>ffd3d193c71e</td>\n      <td>blood_vessel</td>\n      <td>[[[42, 92], [41, 92], [40, 92], [39, 92], [38,...</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n      <td>[14393 12 14904 20 15415 23 15925 28 16434 40 ...</td>\n    </tr>\n    <tr>\n      <th>17515</th>\n      <td>ffd3d193c71e</td>\n      <td>blood_vessel</td>\n      <td>[[[287, 480], [286, 480], [285, 480], [284, 48...</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n      <td>[140243 6 140750 13 141261 15 141772 17 142284...</td>\n    </tr>\n    <tr>\n      <th>17516</th>\n      <td>ffd3d193c71e</td>\n      <td>blood_vessel</td>\n      <td>[[[493, 388], [492, 388], [491, 388], [490, 38...</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n      <td>[244001 5 244512 7 244603 6 245023 9 245112 11...</td>\n    </tr>\n    <tr>\n      <th>17517</th>\n      <td>ffd3d193c71e</td>\n      <td>blood_vessel</td>\n      <td>[[[64, 15], [63, 15], [62, 15], [61, 15], [61,...</td>\n      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n      <td>[27652 5 28162 9 28673 12 29185 13 29697 14 30...</td>\n    </tr>\n  </tbody>\n</table>\n<p>17518 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "save_df = False # save only once\n",
    "if save_df:\n",
    "    train_df_new = train_dataset.dataset\n",
    "    train_df_new.to_excel(os.path.join(data_directory,\"new_train.xlsx\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now use RandStainNA to augment and normalize all of the training images:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
