{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "# from pycocotools import _mask as coco_mask\n",
    "import typing as t\n",
    "import zlib\n",
    "import torch\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Image as show_image\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage.measure import regionprops_table, label, regionprops\n",
    "from pycocotools import _mask as coco_mask\n",
    "import gc\n",
    "import warnings\n",
    "import torchvision.transforms as T\n",
    "import segmentation_models_pytorch as smp\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import cv2\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class model_config:\n",
    "    current_fold = 0\n",
    "    key = \"BT\" #\"MoCoV2\"\n",
    "    pretrained_resnet = False\n",
    "    seed = 42\n",
    "    train_batch_size = 8\n",
    "    valid_batch_size = 16\n",
    "    epochs = 200  # ~15 minutes per epoch\n",
    "    learning_rate = 0.0014 # 0.001 for bs=16\n",
    "    scheduler = \"CosineAnnealingLR\"\n",
    "    num_training_samples = 5499\n",
    "    T_max = int(\n",
    "        num_training_samples / train_batch_size * epochs)  # number of iterations for a full cycle, need to change for different # of iterations. (iteration = batch size)\n",
    "    weight_decay = 1e-6  # explore different weight decay (Adam optimizer)\n",
    "    n_accumulate = 1\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    iters_to_accumulate = max(1, 32 // train_batch_size)  # for scaling accumulated gradients\n",
    "    eta_min = 1e-5\n",
    "    model_save_directory = os.path.join(os.getcwd(), \"model\",\n",
    "                                        \"seresnext_attention_dropout_dilation_v2_retry\")\n",
    "\n",
    "# sets the seed of the entire notebook so results are the same every time we run for reproducibility. no randomness, everything is controlled.\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)  #numpy specific random\n",
    "    random.seed(seed)  # python specific random (also for albumentation augmentations)\n",
    "    torch.manual_seed(seed)  # torch specific random\n",
    "    torch.cuda.manual_seed(seed)  # cuda specific random\n",
    "    # when running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  # when deterministic = true, benchmark = False, otherwise might not be deterministic\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # set a fixed value for the hash seed, for hases like dictionary\n",
    "\n",
    "set_seed(model_config.seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class HubmapDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs, transforms):\n",
    "        self.transforms = transforms\n",
    "        self.imgs = imgs\n",
    "        self.name_indices = [os.path.splitext(os.path.basename(i))[0] for i in imgs]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        img_path = self.imgs[idx]\n",
    "        name = self.name_indices[idx]\n",
    "        array = tiff.imread(img_path)\n",
    "        img = Image.fromarray(array)\n",
    "        img = self.transforms(img)\n",
    "        return img, name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "['\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\train_overlap\\\\images\\\\5631a47d5b0c.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\train_overlap\\\\images\\\\5631a47d5b0c_bot_right.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\train_overlap\\\\images\\\\2fd7649afbc1.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\train_overlap\\\\images\\\\2fd7649afbc1_top_right.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\train_overlap\\\\images\\\\88c95fb9fb14.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\train_overlap\\\\images\\\\88c95fb9fb14_bot_right.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\train_overlap\\\\images\\\\dd690b7d9a47.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\train_overlap\\\\images\\\\dd690b7d9a47_top_right.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\train_overlap\\\\images\\\\dd690b7d9a47_bot_right.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\train_overlap\\\\images\\\\5566406c59ee.tif']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "debug = True\n",
    "model_path = r\"C:\\Users\\labuser\\hubmap\\unet++_resnet50\\model\\seresnext_attention_dropout_dilation_v3\\best_epoch-00.pt\"\n",
    "base_dir = Path('/kaggle/input/hubmap-hacking-the-human-vasculature')\n",
    "image_paths = r\"\\\\fatherserverdw\\Kevin\\hubmap\\train_overlap\\images\"\n",
    "test_paths = [os.path.join(image_paths,x) for x in os.listdir(image_paths) if x.endswith(\".tif\")][0:10] #load all train and debug or do just first hundreds\n",
    "test_paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "test_transforms = T.Compose([T.PILToTensor(),T.ConvertImageDtype(torch.float32)]) # Size C x H x W tensor with float dtype\n",
    "\n",
    "dataset_test = HubmapDataset(test_paths, transforms = test_transforms)\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = smp.UnetPlusPlus(encoder_name=\"se_resnext50_32x4d\", encoder_weights=None, encoder_depth = 5, decoder_channels = [512, 256, 128, 64, 32], activation='sigmoid',\n",
    "                             in_channels=3, classes=1, decoder_attention_type=\"scse\", decoder_use_batchnorm=True,\n",
    "                             aux_params={\"classes\": 1, \"pooling\": \"max\", \"dropout\": 0.5})\n",
    "    model.to(device)  # model to gpu\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:01,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max of prob prediction is 0.029573699459433556\n",
      "mean of prob prediction is 8.378188067581505e-05\n",
      "min of prob prediction is: 4.66595811303705e-05\n",
      "max of prob prediction is 0.029575519263744354\n",
      "mean of prob prediction is 8.379008795600384e-05\n",
      "min of prob prediction is: 4.667925168178044e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max of prob prediction is 0.029575254768133163\n",
      "mean of prob prediction is 8.378141501452774e-05\n",
      "min of prob prediction is: 4.667043685913086e-05\n",
      "max of prob prediction is 0.029575519263744354\n",
      "mean of prob prediction is 8.379008795600384e-05\n",
      "min of prob prediction is: 4.667925168178044e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:00<00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max of prob prediction is 0.02957586571574211\n",
      "mean of prob prediction is 8.37851403048262e-05\n",
      "min of prob prediction is: 4.667435132432729e-05\n",
      "max of prob prediction is 0.02956826239824295\n",
      "mean of prob prediction is 8.380161307286471e-05\n",
      "min of prob prediction is: 4.666954555432312e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:00<00:00,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max of prob prediction is 0.02957264333963394\n",
      "mean of prob prediction is 8.379553764825687e-05\n",
      "min of prob prediction is: 4.667065877583809e-05\n",
      "max of prob prediction is 0.02956826239824295\n",
      "mean of prob prediction is 8.380161307286471e-05\n",
      "min of prob prediction is: 4.666954555432312e-05\n",
      "max of prob prediction is 0.02957719750702381\n",
      "mean of prob prediction is 8.379673818126321e-05\n",
      "min of prob prediction is: 4.667021130444482e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max of prob prediction is 0.029574550688266754\n",
      "mean of prob prediction is 8.379123755730689e-05\n",
      "min of prob prediction is: 4.6665674744872376e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "id_list, heights, widths, prediction_strings = [],[],[],[]\n",
    "with torch.no_grad():\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    for img, idx in tqdm(test_dl):\n",
    "        model.eval() #eval stage\n",
    "        img = img.to(device)\n",
    "        prediction, _  = model(img)\n",
    "        # prob_prediction = nn.Sigmoid()(prediction)\n",
    "        prediction = torch.squeeze(prediction)\n",
    "#         print(\"prob_prediction is {}\".format(prob_prediction))\n",
    "        print(\"max of prob prediction is {}\".format(torch.max(prediction)))\n",
    "        print(\"mean of prob prediction is {}\".format(torch.mean(prediction)))\n",
    "        print(\"min of prob prediction is: {}\".format(torch.min(prediction)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
