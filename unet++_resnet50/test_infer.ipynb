{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Official, more updated code is in Kaggle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "# from pycocotools import _mask as coco_mask\n",
    "import typing as t\n",
    "import zlib\n",
    "import torch\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Image as show_image\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage.measure import regionprops_table, label, regionprops\n",
    "from pycocotools import _mask as coco_mask\n",
    "import gc\n",
    "import warnings\n",
    "import torchvision.transforms as T\n",
    "import segmentation_models_pytorch as smp\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import cv2\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "# model configs, note that key is for the different type of resnet50's available for use from lunit\n",
    "class model_config:\n",
    "    seed = 42\n",
    "    key = \"MoCoV2\"\n",
    "    train_batch_size = 8\n",
    "    valid_batch_size = 8\n",
    "    epochs = 5\n",
    "    CV_fold = 5\n",
    "    learning_rate = 0.001\n",
    "    scheduler = \"CosineAnnealingLR\"\n",
    "    T_max = int(30000 / train_batch_size * epochs)  # for cosineannealingLR, explore different values\n",
    "    weight_decay = 1e-6  # explore different weight decay (Adam optimizer)\n",
    "    n_accumulate = 1\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    iters_to_accumulate = max(1, 32 // train_batch_size)  # for scaling accumulated gradients\n",
    "    eta_min = 1e-5\n",
    "    dice_alpha = 0.5\n",
    "    bce_alpha = 0.5\n",
    "    binary_threshold = 0.3\n",
    "    model_save_directory = os.path.join(os.getcwd(), \"model\",\n",
    "                                        str(key))  #assuming os.getcwd is the current training script directory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# sets the seed of the entire notebook so results are the same every time we run for reproducibility. no randomness, everything is controlled.\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)  #numpy specific random\n",
    "    random.seed(seed)  # python specific random (also for albumentation augmentations)\n",
    "    torch.manual_seed(seed)  # torch specific random\n",
    "    torch.cuda.manual_seed(seed)  # cuda specific random\n",
    "    # when running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  # when deterministic = true, benchmark = False, otherwise might not be deterministic\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # set a fixed value for the hash seed, for hases like dictionary\n",
    "set_seed(model_config.seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "# configurations:\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "debug = True\n",
    "model_paths = glob(r'C:\\Users\\Kevin\\PycharmProjects\\hubmap\\unet++_resnet50\\model\\MoCoV2\\best_epoch*.pt') #ensembles\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if debug:\n",
    "    test_paths = glob(r'\\\\fatherserverdw\\Kevin\\hubmap\\unet++\\images\\*.tif')[0:100] #load all train and debug or do just first hundreds\n",
    "else:\n",
    "    test_paths = glob(r'\\\\fatherserverdw\\Kevin\\hubmap\\test*.tif')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "data": {
      "text/plain": "['C:\\\\Users\\\\Kevin\\\\PycharmProjects\\\\hubmap\\\\unet++_resnet50\\\\model\\\\MoCoV2\\\\best_epoch-02.pt',\n 'C:\\\\Users\\\\Kevin\\\\PycharmProjects\\\\hubmap\\\\unet++_resnet50\\\\model\\\\MoCoV2\\\\best_epoch-03.pt']"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_paths = model_paths[2:4]\n",
    "model_paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "data": {
      "text/plain": "['\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0a993633aa5e.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0a43459733e7.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0ab9d193fcf6.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0acd70e887b3.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0ae9282b7594.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0b89ab7f9f07.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0b935dd9ef6a.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0b989fe8238f.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0b8029db1fb4.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0ba172f33ea6.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0bd23d24a875.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0be9b14718b9.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0c5c322a104a.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0c3086bd8efb.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0c54942878fa.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0cb47c96bda2.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0cc564c74306.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0ce440ad7080.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0cf58cc68215.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0d6c0cfee2db.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0d9d65340ef8.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0d77d32da5e2.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0dce2b8d2c25.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0e8aed930dc6.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0e9cea4fd861.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0e9651f77684.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0f5b52a768e2.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0f6e1cb07f74.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0f960d864969.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\0ff188f666c5.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\01a7fca6263b.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1a0d5fc5d2f7.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1a0daccec1db.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1a4ab6091fe5.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1a05f1dc34fc.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1a54cda8f32d.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1a91d04d00d5.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1a785cc0d167.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1aeae455caeb.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1b0f943da76c.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1b2d34c9e9fe.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1b5da995f08e.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1b60cea2100c.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1b410cd56dcb.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1b2122736cd7.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1bb52a550a23.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1bd79e5bde8a.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1bd726055ad8.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1c6c39a22324.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1c8af4861691.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1c46f36cf55c.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1c0295c1d01d.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1ca8bcb0e27f.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1cd3632761d2.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1d8aa548c370.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1daf55f162a1.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1dbec7df021e.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1de075d4ae93.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1e0efbb8979f.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1e2fd6c2950d.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1e3fe5b348ca.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1e14b9acc9b9.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1ea1a75f6051.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1ed324bad445.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1f0d3cd4b621.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1f5348824ad2.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\1fc1c6cc515a.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\02cf5c2db152.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\02f563532696.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2a4cc81cc5d6.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2a9e6a294e2b.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2a127f0ae506.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2a577425c773.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2aaf9e8db9d8.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2ac4cfbb7405.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2ad1b19b87df.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2af2792c8e0c.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2b1cf5bbc9ea.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2b7c5682bb5c.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2bb6adc62561.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2be23bada1e8.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2befa0c506b5.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2c5bd755f831.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2c369bf03bd4.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2c735ec7ce1c.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2cad7b97ea7e.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2cb88bf3ed30.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2d0c1b760913.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2d97cd20538a.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2d232dbe41bb.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2d2093e38e39.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2daadbc3fe2d.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2daf04a8f13b.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2dbb4700f7be.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2e00a0fe807c.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2e0c92f0c9df.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2e02a3e00059.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2e3a658a8c8e.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2e51dff130b7.tif',\n '\\\\\\\\fatherserverdw\\\\Kevin\\\\hubmap\\\\unet++\\\\images\\\\2e7951162645.tif']"
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "def encode_binary_mask(mask: np.ndarray) -> t.Text:\n",
    "  \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n",
    "\n",
    "  # check input mask --\n",
    "  if mask.dtype != bool:\n",
    "    raise ValueError(\n",
    "        \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n",
    "        mask.dtype)\n",
    "\n",
    "  mask = np.squeeze(mask)\n",
    "  if len(mask.shape) != 2:\n",
    "    raise ValueError(\n",
    "        \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n",
    "        mask.shape)\n",
    "\n",
    "  # convert input mask to expected COCO API input --\n",
    "  mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "  mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "  mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "  # RLE encode mask --\n",
    "  encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "  # compress and base64 encoding --\n",
    "  binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "  base64_str = base64.b64encode(binary_str)\n",
    "  return base64_str"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "class HubmapDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs, transforms):\n",
    "        self.transforms = transforms\n",
    "        self.imgs = imgs\n",
    "        self.name_indices = [os.path.splitext(os.path.basename(i))[0] for i in imgs]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        img_path = self.imgs[idx]\n",
    "        name = self.name_indices[idx]\n",
    "        img = tiff.imread(img_path)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transforms(img)\n",
    "        return img, name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "def remove_elements_below_threshold(arr, threshold):\n",
    "    return [x for x in arr if x >= threshold]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def process_pred(prob_prediction):\n",
    "    binary_prediction = prob_prediction > model_config.binary_threshold #(probability threshold)\n",
    "    binary_prediction = binary_prediction.cpu().numpy()\n",
    "    num_classes = len(np.unique(binary_prediction))\n",
    "    if num_classes == 1: #empty predictions:\n",
    "        label_img = np.zeros((512,512),dtype=np.uint8)\n",
    "        confidences = []\n",
    "    else:\n",
    "        label_img = label(binary_prediction.astype('bool'))\n",
    "        tb = regionprops_table(label_img, properties=['bbox', 'coords'])\n",
    "        tt = pd.DataFrame(tb)\n",
    "        bboxes = tt[['bbox-1', 'bbox-0', 'bbox-3', 'bbox-2']].values #min_x,min_y,max_x,max_y\n",
    "        confidences = []\n",
    "        for bbox in bboxes:\n",
    "            min_x = bbox[0]\n",
    "            min_y = bbox[1]\n",
    "            max_x = bbox[2]\n",
    "            max_y = bbox[3]\n",
    "            label_img_probs = prob_prediction[min_y:max_y,min_x:max_x]\n",
    "            confidence = label_img_probs.cpu().numpy().flatten()\n",
    "            confidence = remove_elements_below_threshold(confidence,threshold=0.001)\n",
    "            confidence = np.mean(confidence)\n",
    "            confidences.append(confidence)\n",
    "    return label_img, confidences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "test_transforms = T.Compose([T.PILToTensor(),T.ConvertImageDtype(torch.float32), T.Normalize(mean=[0.6801, 0.4165, 0.6313], std=[0.1308, 0.2094, 0.1504])]) # Size C x H x W tensor with float dtype\n",
    "# maybe try including normalization to images for test_transform\n",
    "\n",
    "dataset_test = HubmapDataset(test_paths, transforms = test_transforms)\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = smp.UnetPlusPlus(encoder_name=\"resnet50\", encoder_weights=None, activation=None,\n",
    "                             in_channels=3, classes=1, decoder_use_batchnorm=True)\n",
    "    model.to(device)  # model to gpu\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [00:15<00:39,  1.80it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[209], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_path \u001B[38;5;129;01min\u001B[39;00m model_paths:\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m img, idx \u001B[38;5;129;01min\u001B[39;00m tqdm(test_dl):\n\u001B[1;32m----> 6\u001B[0m         model\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      7\u001B[0m         model\u001B[38;5;241m.\u001B[39meval() \u001B[38;5;66;03m#eval stage\u001B[39;00m\n\u001B[0;32m      8\u001B[0m         img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\.conda\\envs\\hubmap\\lib\\site-packages\\torch\\serialization.py:809\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    808\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(UNSAFE_MESSAGE \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 809\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _load(opened_zipfile, map_location, pickle_module, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m    810\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights_only:\n\u001B[0;32m    811\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\hubmap\\lib\\site-packages\\torch\\serialization.py:1172\u001B[0m, in \u001B[0;36m_load\u001B[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1170\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m   1171\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[1;32m-> 1172\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1174\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[0;32m   1176\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\.conda\\envs\\hubmap\\lib\\site-packages\\torch\\serialization.py:1142\u001B[0m, in \u001B[0;36m_load.<locals>.persistent_load\u001B[1;34m(saved_id)\u001B[0m\n\u001B[0;32m   1140\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1141\u001B[0m     nbytes \u001B[38;5;241m=\u001B[39m numel \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_element_size(dtype)\n\u001B[1;32m-> 1142\u001B[0m     typed_storage \u001B[38;5;241m=\u001B[39m \u001B[43mload_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_maybe_decode_ascii\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1144\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m typed_storage\n",
      "File \u001B[1;32m~\\.conda\\envs\\hubmap\\lib\\site-packages\\torch\\serialization.py:1116\u001B[0m, in \u001B[0;36m_load.<locals>.load_tensor\u001B[1;34m(dtype, numel, key, location)\u001B[0m\n\u001B[0;32m   1112\u001B[0m storage \u001B[38;5;241m=\u001B[39m zip_file\u001B[38;5;241m.\u001B[39mget_storage_from_record(name, numel, torch\u001B[38;5;241m.\u001B[39mUntypedStorage)\u001B[38;5;241m.\u001B[39m_typed_storage()\u001B[38;5;241m.\u001B[39m_untyped_storage\n\u001B[0;32m   1113\u001B[0m \u001B[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001B[39;00m\n\u001B[0;32m   1114\u001B[0m \u001B[38;5;66;03m# stop wrapping with TypedStorage\u001B[39;00m\n\u001B[0;32m   1115\u001B[0m typed_storage \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstorage\u001B[38;5;241m.\u001B[39mTypedStorage(\n\u001B[1;32m-> 1116\u001B[0m     wrap_storage\u001B[38;5;241m=\u001B[39m\u001B[43mrestore_location\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m   1117\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m   1118\u001B[0m     _internal\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   1120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typed_storage\u001B[38;5;241m.\u001B[39m_data_ptr() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1121\u001B[0m     loaded_storages[key] \u001B[38;5;241m=\u001B[39m typed_storage\n",
      "File \u001B[1;32m~\\.conda\\envs\\hubmap\\lib\\site-packages\\torch\\serialization.py:217\u001B[0m, in \u001B[0;36mdefault_restore_location\u001B[1;34m(storage, location)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_restore_location\u001B[39m(storage, location):\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, _, fn \u001B[38;5;129;01min\u001B[39;00m _package_registry:\n\u001B[1;32m--> 217\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    219\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\.conda\\envs\\hubmap\\lib\\site-packages\\torch\\serialization.py:187\u001B[0m, in \u001B[0;36m_cuda_deserialize\u001B[1;34m(obj, location)\u001B[0m\n\u001B[0;32m    185\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mUntypedStorage(obj\u001B[38;5;241m.\u001B[39mnbytes(), device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(location))\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 187\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\hubmap\\lib\\site-packages\\torch\\_utils.py:74\u001B[0m, in \u001B[0;36m_cuda\u001B[1;34m(self, device, non_blocking, **kwargs)\u001B[0m\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     73\u001B[0m         device \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m---> 74\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice(device):\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_sparse:\n\u001B[0;32m     76\u001B[0m         new_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39msparse, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\hubmap\\lib\\site-packages\\torch\\cuda\\__init__.py:318\u001B[0m, in \u001B[0;36mdevice.__exit__\u001B[1;34m(self, type, value, traceback)\u001B[0m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__enter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprev_idx \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39m_exchange_device(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39midx)\n\u001B[1;32m--> 318\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__exit__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mtype\u001B[39m: Any, value: Any, traceback: Any):\n\u001B[0;32m    319\u001B[0m     torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39m_exchange_device(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprev_idx)\n\u001B[0;32m    320\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "id_list, heights, widths, prediction_strings = [],[],[],[]\n",
    "with torch.no_grad():\n",
    "    for model_path in model_paths:\n",
    "        for img, idx in tqdm(test_dl):\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            model.eval() #eval stage\n",
    "            img = img.to(device)\n",
    "            prediction = model(img)\n",
    "            prob_prediction = nn.Sigmoid()(prediction)\n",
    "            prob_prediction = torch.squeeze(prob_prediction)\n",
    "            # print(\"mean is: {}\".format(torch.mean(prob_prediction)))\n",
    "            # print(\"max is: {}\".format(torch.max(prob_prediction)))\n",
    "            # print(\"min is: {}\".format(torch.min(prob_prediction)))\n",
    "            label_img, confidences = process_pred(prob_prediction)\n",
    "            binmasks = []\n",
    "            for idx1 in range(len(confidences)):\n",
    "                binmask = label_img == idx1\n",
    "                binmasks.append(binmask)\n",
    "\n",
    "            pred_string = \"\"\n",
    "            for idx2, (binmask, confidence) in enumerate(zip(binmasks, confidences)):\n",
    "                encoded = encode_binary_mask(binmask)\n",
    "                if idx2 == 0: #beginning, no space\n",
    "                    pred_string += f\"0 {confidence:0.4f} {encoded.decode('utf-8')}\"\n",
    "                else:\n",
    "                    pred_string += f\" 0 {confidence:0.4f} {encoded.decode('utf-8')}\"\n",
    "            h = img.size()[2]\n",
    "            w = img.size()[3]\n",
    "            id_list.append(idx[0])\n",
    "            heights.append(h)\n",
    "            widths.append(w)\n",
    "            prediction_strings.append(pred_string)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id  height  width  \\\n",
      "0    0a993633aa5e     512    512   \n",
      "1    0a43459733e7     512    512   \n",
      "2    0ab9d193fcf6     512    512   \n",
      "3    0acd70e887b3     512    512   \n",
      "4    0ae9282b7594     512    512   \n",
      "..            ...     ...    ...   \n",
      "195  2e0c92f0c9df     512    512   \n",
      "196  2e02a3e00059     512    512   \n",
      "197  2e3a658a8c8e     512    512   \n",
      "198  2e51dff130b7     512    512   \n",
      "199  2e7951162645     512    512   \n",
      "\n",
      "                                     prediction_string  \n",
      "0    0 0.3550 eNodjskOwjAMRH/JztJF4opIU8c+sRZEWwptJ...  \n",
      "1                                                       \n",
      "2    0 0.7958 eNozSApMNzSNiIv0M/I38Dc0AGF/I7+snDBTv...  \n",
      "3                                                       \n",
      "4                                                       \n",
      "..                                                 ...  \n",
      "195  0 0.9126 eNpFUG13sjAM/UsJBR/HDr6wMUehBB/FiS/Tg...  \n",
      "196  0 0.9144 eNoljEsKgDAMBa/0mtbfBQTRJF2IICqIUsGV9...  \n",
      "197  0 0.9009 eNpFjM0KAjEMhF8pP93uQVnRgwvdJnEvCgrSg...  \n",
      "198                                                     \n",
      "199  0 0.8570 eNotj+tqwzAMRl9JviWLBhtjVbvYsQVry6C2S...  \n",
      "\n",
      "[200 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = id_list\n",
    "submission['height'] = heights\n",
    "submission['width'] = widths\n",
    "submission['prediction_string'] = prediction_strings\n",
    "# submission.to_csv(\"submission.csv\",index=False)\n",
    "print(submission)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
